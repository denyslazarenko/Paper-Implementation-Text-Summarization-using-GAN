# Learning to Encode Text as Human-Readable Summaries using Generative Adversarial Networks

#### Implementation of the paper [**Learning to Encode Text as Human-Readable Summaries using Generative Adversarial Networks**](https://arxiv.org/pdf/1810.02851.pdf).


![short-version](./presentation/tum-resources/images/logo.png)

## Sources
1. [Code to obtain the CNN / Daily Mail dataset (non-anonymized) for summarization. Accessed: November 20, 2019](https://github.com/abisee/cnn-dailymail)    
2. [Code for the ACL 2017 paper "Get To The Point: Summarization with Pointer-Generator Networks". Accessed: November 28, 2019](https://github.com/abisee/pointer-generator)    
3. [Abigail See, Peter J. Liu, Christopher D. Manning. Get To The Point: Summarization with Pointer-Generator Networks, 2017](https://arxiv.org/pdf/1704.04368.pdf)    
4. [Attention RNNs in Keras. Accessed: December 2, 2019](https://github.com/datalogue/keras-attention)    
5. [Jason Brownlee. Blog post: "How to Develop a Wasserstein Generative Adversarial Network (WGAN) From Scratch". Accessed: December 21, 2019](https://machinelearningmastery.com/how-to-code-a-wasserstein-generative-adversarial-network-wgan-from-scratch/)
